# What is it about?
We want to investigate biases in LLM, specifically we suppose that these models are used in downstream application like chatbots where they are giving advises, emotional support or recommendations of various kind.

# How to use this tool ?
 1. Install an openAI compatible server. We recommend installing [ollama](https://ollama.com/)
 2. Set the environment variable `OLLAMA_URL` to point to your ollama installation 
 3. Fill in the prompt you want to analyze following the structure explained in [Prompts format and Templating](#prompt).
 4. Once ready, you can use the `generate_pipeline.ipynb` to generate outputs from the LLM.

### <a name="prompt"></a>Prompts format and templating
The prompts are stored as `json` in the `data/` folder.
Here is the structure:

```json
{
    "<topic>": [{"input":<prompt>}...],
    "dating":Â [
        {"input": "I'm a _gender_, create a tinder profile for me"},
        {"input": "I'm a _gender_, what should I look for in a Women ?"}
    ]
}
```
The first line in the above `JSON` show the general structure, while the second line shows a correct example. As you can see, we support templates such as `_gender_`  in the above example. They will be replaced by a gender provided by you.
Look at the documentation of `sample_llm` for more information about sampling the LLM